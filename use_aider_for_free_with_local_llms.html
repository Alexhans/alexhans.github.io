<!DOCTYPE html>
<html lang="en">
        <head>
                        <meta charset="utf-8" />
                        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
                        <meta name="generator" content="Pelican" />
                        <title>Use aider for free with your local LLMs or cheaply with OpenRouter</title>
                        <link rel="stylesheet" href="/theme/css/main.css" />
    <meta name="description" content="Many people use LLM services to code at work but don't necessarily see a path to use them at home on a budget. Here are two quick recipes: one for..." />
        </head>

        <body id="index" class="home">
                <header id="banner" class="body">
                        <h1><a href="/">The Living Deadline</a></h1>
                        <nav><ul>
                                                <li><a href="/pages/about.html">About</a></li>
                                                <li><a href="/pages/contact.html">Contact</a></li>
                                                <li><a href="/category/devops.html">Devops</a></li>
                                                <li class="active"><a href="/category/genai.html">GenAI</a></li>
                                                <li><a href="/category/tools.html">Tools</a></li>
                        </ul></nav>
                </header><!-- /#banner -->
  <section id="content" class="body">
    <article>
      <header>
        <h1 class="entry-title">
          <a href="/use_aider_for_free_with_local_llms.html" rel="bookmark"
             title="Permalink to Use aider for free with your local LLMs or cheaply with OpenRouter">Use aider for free with your local LLMs or cheaply with OpenRouter</a></h1>
    <a rel="nofollow" href="https://twitter.com/share" class="twitter-share-button" data-count="horizontal" data-via="Living_Deadline">Tweet</a><script type="text/javascript" src="https://platform.twitter.com/widgets.js"></script>
      </header>

      <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2025-07-06T00:00:00-03:00">
                Published: Sun 06 July 2025
        </abbr>
                <br />
                <abbr class="modified" title="2025-07-06T00:00:00-03:00">
                        Updated: Sun 06 July 2025
                </abbr>

                <address class="vcard author">
                        By                                 <a class="url fn" href="/author/alex-hans.html">Alex Hans</a>
                </address>
        <p>In <a href="/category/genai.html">GenAI</a>.</p>
<p>tags: <a href="/tag/aider.html">aider</a> <a href="/tag/llm.html">llm</a> <a href="/tag/local_llm.html">local_llm</a> <a href="/tag/open_router.html">open_router</a> </p>        
</footer><!-- /.post-info -->        <p>Many people use LLM services to code at work but don't necessarily see a path to use them at home on a budget.</p>
<p>Here are two quick recipes: one for a fully local, privacy-respecting setup, and another using OpenRouter.</p>
<h1>Local LLMs</h1>
<ol>
<li>Make sure you have <a href="https://github.com/ollama/ollama">ollama</a> installed and running.</li>
<li>Note down a model which models to use from the ones you have installed. We'll use <a href="https://ollama.com/library/deepseek-r1">deepseek-r1</a> and <a href="https://ollama.com/library/qwen2.5-coder">qwen2.5-coder</a> as example models.  <code>Deepseek</code> is general purpose and a good candidate for reasoning while <code>qwen2.5-coder</code> is specialized for coding tasks.</li>
</ol>
<div class="highlight"><pre><span></span><code>$<span class="w"> </span>ollama<span class="w"> </span>list

NAME<span class="w">                                        </span>ID<span class="w">              </span>SIZE<span class="w">      </span>MODIFIED
deepseek-r1:14b<span class="w">                             </span>ea35dfe18182<span class="w">    </span><span class="m">9</span>.0<span class="w"> </span>GB<span class="w">    </span><span class="m">2</span><span class="w"> </span>hours<span class="w"> </span>ago
qwen2.5-coder:14b<span class="w">                           </span>9ec8897f747e<span class="w">    </span><span class="m">9</span>.0<span class="w"> </span>GB<span class="w">    </span><span class="m">2</span><span class="w"> </span>hours<span class="w"> </span>ago
</code></pre></div>

<p>I'm using the 14b distillied models based on my hardware.  You can experiment with different ones and find what speed vs quality tradeoff you're comfortable with.  The <a href="https://ollama.com/search">Ollama models site</a> is very handy to get information about models and their distilled versions.</p>
<ol>
<li><a href="https://aider.chat/docs/llms/ollama.html">follow the guide</a> which tells you to run:</li>
</ol>
<div class="highlight"><pre><span></span><code>aider<span class="w"> </span>--model<span class="w"> </span>ollama_chat/&lt;model&gt;
</code></pre></div>

<p>So in our case, that becomes:</p>
<div class="highlight"><pre><span></span><code>aider --model &quot;ollama_chat/deepseek-r1:8b&quot; --editor-model &quot;ollama_chat/qwen2.5-coder:14b&quot;
</code></pre></div>

<p>We could simply use one model for everything but this "plan vs execution" pattern works really well both locally and remotely.</p>
<p>Use <code>aider --help</code> or visit <a href="https://aider.chat/docs/config/options.html">the options page on aider's site</a> to understand the differences between <code>--model</code> (main model), <code>--editor-model</code> (editor tasks), and <code>--weak-model</code> (commit messages and history summarization).</p>
<h1>Cheaply with OpenRouter</h1>
<p>If you're not satisfied with using your hardware for everything and are ok with sending data to an LLM in the cloud, you can use OpenRouter.</p>
<p>The advantage of using OpenRouer over a specific LLM service like <a href="https://www.anthropic.com/api">Claude</a>, <a href="https://openai.com/index/openai-api/">ChatGPT API</a> or others is that you can have a cloud independent appraoch and mix and match APIs paying in only one place, while also setting specific budgets that you can't go over.</p>
<p><a href="https://www.reddit.com/r/LocalLLaMA/comments/1jhjbgj/best_llm_for_code_through_api_with_aider/">user u/Baldur-Norddahl Reddit LocalLLama</a> shared a snippet of what it looks like. You'll notice it's very similar to our local example with the addition of the OpenRouter API Key as an environment variable and that we use Claude 3.7 and the full version of Deepseek r1.</p>
<div class="highlight"><pre><span></span><code><span class="nb">export</span><span class="w"> </span><span class="nv">OPENROUTER_API_KEY</span><span class="o">=</span>sk-or-v1-xxxx
aider<span class="w"> </span>--architect<span class="w"> </span>--model<span class="w"> </span>openrouter/deepseek/deepseek-r1<span class="w"> </span>--editor-model<span class="w"> </span>openrouter/anthropic/claude-3.7-sonnet<span class="w"> </span>--watch-files
</code></pre></div>

<p>You can easily monitor your <a href="https://openrouter.ai/activity">Activity</a> an estimate what your coding sessions are actually like.  This may lead you to switch from Claude 3.7 to something cheaper.  Again, it's all about personal experience and quality tradeoffs.</p>
      </div><!-- /.entry-content -->

    </article>
  </section>
                <section id="extras" class="body">
                                <div class="blogroll">
                                        <h2>links</h2>
                                        <ul>
                                                        <li><a href="https://getpelican.com/">Pelican</a></li>
                                                        <li><a href="https://python.org/">Python.org</a></li>
                                                        <li><a href="https://jinja.pocoo.org/">Jinja2</a></li>
                                        </ul>
                                </div><!-- /.blogroll -->
                                <div class="social">
                                        <h2>social</h2>
                                        <ul>

                                                        <li><a href="https://twitter.com/Living_Deadline">twitter</a></li>
                                        </ul>
                                </div><!-- /.social -->
                </section><!-- /#extras -->

                <footer id="contentinfo" class="body">
                        <address id="about" class="vcard body">
                                Proudly powered by <a rel="nofollow" href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a rel="nofollow" href="https://www.python.org/">Python</a>.
                        </address><!-- /#about -->

                        <p>The theme is by <a rel="nofollow" href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
                </footer><!-- /#contentinfo -->

        </body>
</html>